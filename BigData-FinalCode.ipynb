{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType, IntegerType\n",
    "from pyspark.sql.functions import to_timestamp, upper, col\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, Tokenizer, StopWordsRemover, Word2Vec, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import StringType, DoubleType \n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('BigDataProject').getOrCreate()\n",
    "\n",
    "#change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '4g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','4g')])\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 1 - Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = spark.read.csv(\"/user/efischbein/data/group_project/us_housing_prices\", inferSchema=True, header=True)\n",
    "Public_Schools = spark.read.csv(\"/user/efischbein/data/group_project/Public_Schools.csv\", \\\n",
    "    inferSchema=True, header=True)\n",
    "CPI = spark.read.csv(\"/user/efischbein/data/group_project/CPIHOSNS.csv\", inferSchema=True, header=True)\n",
    "ZVHI = spark.read.csv(\"/user/efischbein/data/group_project/ZHVI_cln.csv\", inferSchema=True, header=True)\n",
    "Income = spark.read.csv(\"/user/efischbein/data/group_project/Census_Income\", inferSchema=True, header=True)\n",
    "pre_2000 = spark.read.csv(\"/user/efischbein/data/group_project/county_pre_2000_data_cln.csv\", header=True)\n",
    "hospital_ratings = spark.read.csv('/user/efischbein/data/group_project/hospital/Hospital_General_Information.csv', \\\n",
    "    header = True)\n",
    "hospital = spark.read.csv('/user/efischbein/data/group_project/hospital/hospitals.csv', header = True)\n",
    "crime = spark.read.csv('/user/efischbein/data/group_project/crime_data_w_population_and_crime_rate.csv',header = True)\n",
    "CountyCrossWalk_Zillow = spark.read.csv('/user/efischbein/data/group_project/zillow_econ/CountyCrossWalk_Zillow.csv',\\\n",
    "    header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 2 - Data Cleanup\n",
    "1. drop extra columns (seller_name, buyer_name, source_url, book, page)\n",
    "2. Dates - limited from 1970-2021\n",
    "3. Sale Price - not null, greater than 0\n",
    "4. City, State - remove null\n",
    "5. Num. Units -  must be 1\n",
    "6. Property Type - remove condos, mobile homes\n",
    "7. Num. Sales - must be greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleanup - drop extra columns\n",
    "df = raw_df.drop(\"seller_name\", \"buyer_name\", \"source_url\", \"book\", \"page\")\n",
    "\n",
    "#Data Cleanup - Dates: 1970 - 2021\n",
    "df = df.withColumn('sale_date', F.to_date(F.unix_timestamp('sale_date', 'yyyy-MM-dd').cast('timestamp')))\n",
    "df = df.filter((F.year(col(\"sale_date\"))<=2021) & (F.year(col(\"sale_date\"))>=1970))\n",
    "\n",
    "#Data Cleanup - Sale Price\n",
    "df = df.withColumn('sale_price', df.sale_price.cast('float'))\n",
    "df = df.filter(col(\"sale_price\").isNotNull()).filter(col(\"sale_price\")>0)\n",
    "\n",
    "#Data Cleanup - remove null cities & states\n",
    "df = df.filter((col(\"city\").isNotNull()) & (col(\"state\").isNotNull()) & \\\n",
    "    (col(\"physical_address\").isNotNull()) & (col(\"zip5\").isNotNull()))\n",
    "\n",
    "#Data Cleanup - View number of units, want to only be 1\n",
    "df = df.filter(col('num_units')==1)\n",
    "\n",
    "#Data Cleanup - filter out condos, mobile homes, rentals\n",
    "df = df.where(~ col(\"property_type\").like(\"%CONDO%\"))\n",
    "df = df.where(~ col(\"property_type\").like(\"%MOBILE%HOME%\"))\n",
    "df = df.where(~ col(\"property_type\").like(\"%RENTALS%\"))\n",
    "\n",
    "#Data Cleanup - filter dataframe based on window function to only show properties with only 1 sale\n",
    "windowSpec = Window().partitionBy(['city','state', 'physical_address', 'zip5']).rangeBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "df = df.withColumn(\"num_sales\", F.count(col('city')).over(windowSpec)).filter(col('num_sales') > 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>state</th><th>zip5</th><th>physical_address</th><th>city</th><th>county</th><th>property_id</th><th>property_type</th><th>sale_price</th><th>num_units</th><th>year_built</th><th>num_sales</th></tr>\n",
       "<tr><td>count</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4409835</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4309742</td><td>4475696</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>78918.27365598557</td><td>0.0</td><td>null</td><td>null</td><td>3.052766666829644E16</td><td>null</td><td>659333.053226582</td><td>1.0</td><td>1971.4363760058027</td><td>3.7982615441263214</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>25360.736490400435</td><td>0.0</td><td>null</td><td>null</td><td>8.301656420043518...</td><td>null</td><td>9080130.91264043</td><td>0.0</td><td>26.98456629791822</td><td>2.76297146640094</td></tr>\n",
       "<tr><td>min</td><td>CA</td><td>02467</td><td>0</td><td>ACTON</td><td>BRONX COUNTY</td><td>0000025</td><td>\"\"\"LO17 PLZ \"\"\"\"C...</td><td>1.0</td><td>1</td><td>1776</td><td>2</td></tr>\n",
       "<tr><td>max</td><td>WA</td><td>98282</td><td>YOUNG AVENUE</td><td>ZEPHYRHILLS</td><td>Wake</td><td>U-35-28-17-0CH-00...</td><td>WELLINGTON WOODS ...</td><td>2.8E9</td><td>1</td><td>2022</td><td>214</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+----------------+---------+------------------+------------------+\n",
       "|summary|  state|              zip5|physical_address|       city|      county|         property_id|       property_type|      sale_price|num_units|        year_built|         num_sales|\n",
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+----------------+---------+------------------+------------------+\n",
       "|  count|4475696|           4475696|         4475696|    4475696|     4475696|             4409835|             4475696|         4475696|  4475696|           4309742|           4475696|\n",
       "|   mean|   null| 78918.27365598557|             0.0|       null|        null|3.052766666829644E16|                null|659333.053226582|      1.0|1971.4363760058027|3.7982615441263214|\n",
       "| stddev|   null|25360.736490400435|             0.0|       null|        null|8.301656420043518...|                null|9080130.91264043|      0.0| 26.98456629791822|  2.76297146640094|\n",
       "|    min|     CA|             02467|               0|      ACTON|BRONX COUNTY|             0000025|\"\"\"LO17 PLZ \"\"\"\"C...|             1.0|        1|              1776|                 2|\n",
       "|    max|     WA|             98282|    YOUNG AVENUE|ZEPHYRHILLS|        Wake|U-35-28-17-0CH-00...|WELLINGTON WOODS ...|           2.8E9|        1|              2022|               214|\n",
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+----------------+---------+------------------+------------------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row count = 4,475,696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 3 - Join Predictive Data Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Public schools - First predictor variable - raw count by zip code\n",
    "num_schools_zip = Public_Schools.groupby('ZIP').count()\n",
    "\n",
    "#join predictor to base table\n",
    "df = df.join(num_schools_zip, df['zip5'] == num_schools_zip['ZIP'], 'left').\\\n",
    "    select(df[\"*\"],num_schools_zip[\"count\"]).na.fill(0).withColumnRenamed('count','zip_num_schools')\n",
    "\n",
    "#Public schools - Second predictor variable - number of schools by city\n",
    "num_schools_city = Public_Schools.groupby('city', 'state').count()\n",
    "\n",
    "#join predictor to base table\n",
    "df = df.join(num_schools_city, (df['city'] == num_schools_city['city']) & \\\n",
    "     (df['state'] == num_schools_city['state']), 'left').\\\n",
    "     select(df[\"*\"],num_schools_city[\"count\"]).na.fill(0).withColumnRenamed('count','city_num_schools')\n",
    "\n",
    "#Public schools - Third predictor variable - Student Teacher Ratio by Zip\n",
    "st_ratio_zip = Public_Schools.filter((col('ENROLLMENT') != -1) & (col('FT_TEACHER') != -1))\n",
    "st_ratio_zip = st_ratio_zip.groupby('ZIP').agg((F.sum(st_ratio_zip.ENROLLMENT) / F.sum(st_ratio_zip.FT_TEACHER)).alias('zip_st_ratio'))\n",
    "#join predictor to base table\n",
    "df = df.join(st_ratio_zip, df['zip5'] == st_ratio_zip['ZIP'], 'left').\\\n",
    "    select(df[\"*\"],st_ratio_zip[\"zip_st_ratio\"])\n",
    "    \n",
    "#Public schools - Fourth predictor variable - Student Teacher Ratio by City\n",
    "st_ratio_city = Public_Schools.filter((col('ENROLLMENT') != -1) & (col('FT_TEACHER') != -1))\n",
    "st_ratio_city = st_ratio_city.groupby('city', 'state').agg((F.sum(st_ratio_city.ENROLLMENT) / F.sum(st_ratio_city.FT_TEACHER)).alias('city_st_ratio'))\n",
    "#join predictor to base table\n",
    "df = df.join(st_ratio_city, (df['city'] == st_ratio_city['city']) & \\\n",
    "    (df['state'] == st_ratio_city['state']), 'left').\\\n",
    "    select(df[\"*\"],st_ratio_city[\"city_st_ratio\"]).na.fill(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>state</th><th>zip5</th><th>physical_address</th><th>city</th><th>county</th><th>property_id</th><th>property_type</th><th>sale_price</th><th>num_units</th><th>year_built</th><th>num_sales</th><th>zip_num_schools</th><th>city_num_schools</th><th>zip_st_ratio</th><th>city_st_ratio</th></tr>\n",
       "<tr><td>count</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4409835</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4309742</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>78918.27365598557</td><td>0.0</td><td>null</td><td>null</td><td>3.052766666829643...</td><td>null</td><td>659333.053226582</td><td>1.0</td><td>1971.4363760058027</td><td>3.7982615441263214</td><td>9.988614508223971</td><td>120.0276138057634</td><td>22.884661353843978</td><td>21.87006647716683</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>25360.73649040043</td><td>0.0</td><td>null</td><td>null</td><td>8.301656420043518...</td><td>null</td><td>9080130.912640434</td><td>0.0</td><td>26.984566297918217</td><td>2.7629714664009404</td><td>6.147428170273346</td><td>207.15393653895927</td><td>6.5338041506411715</td><td>5.769448024528116</td></tr>\n",
       "<tr><td>min</td><td>CA</td><td>02467</td><td>0</td><td>ACTON</td><td>BRONX COUNTY</td><td>0000025</td><td>\"\"\"LO17 PLZ \"\"\"\"C...</td><td>1.0</td><td>1</td><td>1776</td><td>2</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>max</td><td>WA</td><td>98282</td><td>YOUNG AVENUE</td><td>ZEPHYRHILLS</td><td>Wake</td><td>U-35-28-17-0CH-00...</td><td>WELLINGTON WOODS ...</td><td>2.8E9</td><td>1</td><td>2022</td><td>214</td><td>46</td><td>587</td><td>360.0</td><td>40.125</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------+-----------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+-----------------+\n",
       "|summary|  state|             zip5|physical_address|       city|      county|         property_id|       property_type|       sale_price|num_units|        year_built|         num_sales|  zip_num_schools|  city_num_schools|      zip_st_ratio|    city_st_ratio|\n",
       "+-------+-------+-----------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+-----------------+\n",
       "|  count|4475696|          4475696|         4475696|    4475696|     4475696|             4409835|             4475696|          4475696|  4475696|           4309742|           4475696|          4475696|           4475696|           4475696|          4475696|\n",
       "|   mean|   null|78918.27365598557|             0.0|       null|        null|3.052766666829643...|                null| 659333.053226582|      1.0|1971.4363760058027|3.7982615441263214|9.988614508223971| 120.0276138057634|22.884661353843978|21.87006647716683|\n",
       "| stddev|   null|25360.73649040043|             0.0|       null|        null|8.301656420043518...|                null|9080130.912640434|      0.0|26.984566297918217|2.7629714664009404|6.147428170273346|207.15393653895927|6.5338041506411715|5.769448024528116|\n",
       "|    min|     CA|            02467|               0|      ACTON|BRONX COUNTY|             0000025|\"\"\"LO17 PLZ \"\"\"\"C...|              1.0|        1|              1776|                 2|                0|                 0|               0.0|              0.0|\n",
       "|    max|     WA|            98282|    YOUNG AVENUE|ZEPHYRHILLS|        Wake|U-35-28-17-0CH-00...|WELLINGTON WOODS ...|            2.8E9|        1|              2022|               214|               46|               587|             360.0|           40.125|\n",
       "+-------+-------+-----------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+-----------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing CPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date columns\n",
    "CPI = CPI.withColumn('month', F.month(col('DATE')))\n",
    "CPI = CPI.withColumn('year', F.year(col('DATE')))\n",
    "#join predictor to base table\n",
    "df = df.join(CPI, (F.month(df['sale_date']) == CPI['month']) & \\\n",
    "    (F.year(df['sale_date']) == CPI['year']), 'left').\\\n",
    "    select(df[\"*\"],CPI[\"CPIHOSNS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>state</th><th>zip5</th><th>physical_address</th><th>city</th><th>county</th><th>property_id</th><th>property_type</th><th>sale_price</th><th>num_units</th><th>year_built</th><th>num_sales</th><th>zip_num_schools</th><th>city_num_schools</th><th>zip_st_ratio</th><th>city_st_ratio</th><th>CPIHOSNS</th></tr>\n",
       "<tr><td>count</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4409835</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4309742</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>78918.27365598557</td><td>0.0</td><td>null</td><td>null</td><td>3.052766666829642...</td><td>null</td><td>659333.053226582</td><td>1.0</td><td>1971.4363760058027</td><td>3.7982615441263214</td><td>9.988614508223971</td><td>120.0276138057634</td><td>22.884661353843978</td><td>21.870066477166844</td><td>185.14688744052464</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>25360.736490400417</td><td>0.0</td><td>null</td><td>null</td><td>8.301656420043518...</td><td>null</td><td>9080130.912640426</td><td>0.0</td><td>26.984566297918217</td><td>2.762971466400941</td><td>6.147428170273351</td><td>207.15393653895939</td><td>6.533804150641171</td><td>5.769448024528117</td><td>52.39264001611369</td></tr>\n",
       "<tr><td>min</td><td>CA</td><td>02467</td><td>0</td><td>ACTON</td><td>BRONX COUNTY</td><td>0000025</td><td>\"\"\"LO17 PLZ \"\"\"\"C...</td><td>1.0</td><td>1</td><td>1776</td><td>2</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>35.1</td></tr>\n",
       "<tr><td>max</td><td>WA</td><td>98282</td><td>YOUNG AVENUE</td><td>ZEPHYRHILLS</td><td>Wake</td><td>U-35-28-17-0CH-00...</td><td>WELLINGTON WOODS ...</td><td>2.8E9</td><td>1</td><td>2022</td><td>214</td><td>46</td><td>587</td><td>360.0</td><td>40.125</td><td>287.511</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+\n",
       "|summary|  state|              zip5|physical_address|       city|      county|         property_id|       property_type|       sale_price|num_units|        year_built|         num_sales|  zip_num_schools|  city_num_schools|      zip_st_ratio|     city_st_ratio|          CPIHOSNS|\n",
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+\n",
       "|  count|4475696|           4475696|         4475696|    4475696|     4475696|             4409835|             4475696|          4475696|  4475696|           4309742|           4475696|          4475696|           4475696|           4475696|           4475696|           4475696|\n",
       "|   mean|   null| 78918.27365598557|             0.0|       null|        null|3.052766666829642...|                null| 659333.053226582|      1.0|1971.4363760058027|3.7982615441263214|9.988614508223971| 120.0276138057634|22.884661353843978|21.870066477166844|185.14688744052464|\n",
       "| stddev|   null|25360.736490400417|             0.0|       null|        null|8.301656420043518...|                null|9080130.912640426|      0.0|26.984566297918217| 2.762971466400941|6.147428170273351|207.15393653895939| 6.533804150641171| 5.769448024528117| 52.39264001611369|\n",
       "|    min|     CA|             02467|               0|      ACTON|BRONX COUNTY|             0000025|\"\"\"LO17 PLZ \"\"\"\"C...|              1.0|        1|              1776|                 2|                0|                 0|               0.0|               0.0|              35.1|\n",
       "|    max|     WA|             98282|    YOUNG AVENUE|ZEPHYRHILLS|        Wake|U-35-28-17-0CH-00...|WELLINGTON WOODS ...|            2.8E9|        1|              2022|               214|               46|               587|             360.0|            40.125|           287.511|\n",
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZVHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create date column\n",
    "ZVHI = ZVHI.withColumn('Date', F.to_date(F.unix_timestamp('Date', 'MM/dd/yyyy').cast('timestamp')))\n",
    "\n",
    "#filter out nationwide records\n",
    "ZVHI = ZVHI.filter((ZVHI['RegionType'] == 'Msa') & (ZVHI['ZVHI'] > 0)) \\\n",
    "    .groupBy('StateName', 'Date').agg(F.mean(col('ZVHI')) \\\n",
    "    .alias('ZVHI')).orderBy('StateName', 'Date')\n",
    "\n",
    "    #add month, year columns\n",
    "ZVHI = ZVHI.withColumn('month', F.month(col('DATE')))\n",
    "ZVHI = ZVHI.withColumn('year', F.year(col('DATE')))\n",
    "\n",
    "#ZVHI - join on city name\n",
    "df = df.join(ZVHI, \\\n",
    "    (F.month(df['sale_date']) == ZVHI['month']) & (F.year(df['sale_date']) == ZVHI['year']) \\\n",
    "    & (df['state'] == ZVHI['StateName']), 'left') \\\n",
    "    .na.fill(0).drop(\"year\", \"month\", \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>state</th><th>zip5</th><th>physical_address</th><th>city</th><th>county</th><th>property_id</th><th>property_type</th><th>sale_price</th><th>num_units</th><th>year_built</th><th>num_sales</th><th>zip_num_schools</th><th>city_num_schools</th><th>zip_st_ratio</th><th>city_st_ratio</th><th>CPIHOSNS</th><th>StateName</th><th>ZVHI</th></tr>\n",
       "<tr><td>count</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4409835</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4309742</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>4475696</td><td>2819236</td><td>4475696</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>78918.27365598557</td><td>0.0</td><td>null</td><td>null</td><td>3.052766666829642...</td><td>null</td><td>659333.053226582</td><td>1.0</td><td>1971.4363760058027</td><td>3.7982615441263214</td><td>9.988614508223971</td><td>120.0276138057634</td><td>22.884661353843995</td><td>21.87006647716684</td><td>185.1468874405245</td><td>null</td><td>191447.41764069453</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>25360.736490400424</td><td>0.0</td><td>null</td><td>null</td><td>8.301656420043516...</td><td>null</td><td>9080130.912640426</td><td>0.0</td><td>26.984566297918207</td><td>2.762971466400941</td><td>6.1474281702733435</td><td>207.15393653895933</td><td>6.5338041506411715</td><td>5.769448024528117</td><td>52.39264001611371</td><td>null</td><td>171136.8298631848</td></tr>\n",
       "<tr><td>min</td><td>CA</td><td>02467</td><td>0</td><td>ACTON</td><td>BRONX COUNTY</td><td>0000025</td><td>\"\"\"LO17 PLZ \"\"\"\"C...</td><td>1.0</td><td>1</td><td>1776</td><td>2</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>35.1</td><td>CA</td><td>0.0</td></tr>\n",
       "<tr><td>max</td><td>WA</td><td>98282</td><td>YOUNG AVENUE</td><td>ZEPHYRHILLS</td><td>Wake</td><td>U-35-28-17-0CH-00...</td><td>WELLINGTON WOODS ...</td><td>2.8E9</td><td>1</td><td>2022</td><td>214</td><td>46</td><td>587</td><td>360.0</td><td>40.125</td><td>287.511</td><td>WA</td><td>592158.2647058824</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+---------+------------------+\n",
       "|summary|  state|              zip5|physical_address|       city|      county|         property_id|       property_type|       sale_price|num_units|        year_built|         num_sales|   zip_num_schools|  city_num_schools|      zip_st_ratio|    city_st_ratio|         CPIHOSNS|StateName|              ZVHI|\n",
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+---------+------------------+\n",
       "|  count|4475696|           4475696|         4475696|    4475696|     4475696|             4409835|             4475696|          4475696|  4475696|           4309742|           4475696|           4475696|           4475696|           4475696|          4475696|          4475696|  2819236|           4475696|\n",
       "|   mean|   null| 78918.27365598557|             0.0|       null|        null|3.052766666829642...|                null| 659333.053226582|      1.0|1971.4363760058027|3.7982615441263214| 9.988614508223971| 120.0276138057634|22.884661353843995|21.87006647716684|185.1468874405245|     null|191447.41764069453|\n",
       "| stddev|   null|25360.736490400424|             0.0|       null|        null|8.301656420043516...|                null|9080130.912640426|      0.0|26.984566297918207| 2.762971466400941|6.1474281702733435|207.15393653895933|6.5338041506411715|5.769448024528117|52.39264001611371|     null| 171136.8298631848|\n",
       "|    min|     CA|             02467|               0|      ACTON|BRONX COUNTY|             0000025|\"\"\"LO17 PLZ \"\"\"\"C...|              1.0|        1|              1776|                 2|                 0|                 0|               0.0|              0.0|             35.1|       CA|               0.0|\n",
       "|    max|     WA|             98282|    YOUNG AVENUE|ZEPHYRHILLS|        Wake|U-35-28-17-0CH-00...|WELLINGTON WOODS ...|            2.8E9|        1|              2022|               214|                46|               587|             360.0|           40.125|          287.511|       WA| 592158.2647058824|\n",
       "+-------+-------+------------------+----------------+-----------+------------+--------------------+--------------------+-----------------+---------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+---------+------------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit columns\n",
    "income_df = Income.select('Year', 'Geographic Area Name', 'Households!!Estimate!!Median income (dollars)')\n",
    "\n",
    "#clean zip column\n",
    "income_df = income_df.withColumn('Zip', F.substring(col('Geographic Area Name'), -5, 5))\n",
    "\n",
    "pre_2000 = pre_2000.filter(col('Region').contains('County'))\n",
    "pre_2000 = pre_2000.withColumn('County', F.upper(F.substring_index(col('Region'), ' County', 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Income - join on city name\n",
    "df = df.join(income_df, \\\n",
    "             (F.year(df['sale_date']) == income_df['Year']) & (df['zip5'] == income_df['Zip']), 'left')#.select(df[\"*\"],income_df[\"Geographic Area Name\", \"Households!!Estimate!!Median income (dollars)\"])\n",
    "df = df.drop(\"Year\", \"Zip\")\n",
    "\n",
    "#pre_2000 - join on county name\n",
    "df = df.drop(\"year\").join(pre_2000, \\\n",
    "    (F.year(df['sale_date']) == pre_2000['Year']) \\\n",
    "    & (F.upper(df.county) == F.upper(pre_2000['County'])), 'left')\\\n",
    "    .select(df[\"*\"],pre_2000[\"Income\"]).na.fill(0)\n",
    "\n",
    "#create final income field combining the datasets\n",
    "df = df.withColumn('Median_Income', F.when(F.year(col('sale_date')) < 2011, \\\n",
    "    col('Income')).otherwise(col('Households!!Estimate!!Median income (dollars)')))\n",
    "\n",
    "#drop extra columns\n",
    "df = df.drop('StateName', 'Date', 'Year', 'Geographic Area Name', \\\n",
    "    'Households!!Estimate!!Median income (dollars)','Zip','Region', 'County', 'Income','month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>state</th><th>zip5</th><th>physical_address</th><th>city</th><th>property_id</th><th>property_type</th><th>sale_price</th><th>num_units</th><th>year_built</th><th>num_sales</th><th>zip_num_schools</th><th>city_num_schools</th><th>zip_st_ratio</th><th>city_st_ratio</th><th>CPIHOSNS</th><th>ZVHI</th><th>Median_Income</th></tr>\n",
       "<tr><td>count</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4410023</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4309930</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>3804447</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>78916.14287523984</td><td>0.0</td><td>null</td><td>3.052758767985918E16</td><td>null</td><td>659313.0378253771</td><td>1.0</td><td>1971.4367920128634</td><td>3.798283646314337</td><td>9.988419717758548</td><td>120.02769977952958</td><td>22.88439441066564</td><td>21.869880044100768</td><td>185.1464236792117</td><td>191442.83962832842</td><td>44238.60159023118</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>25362.334859900817</td><td>0.0</td><td>null</td><td>8.301647132342966...</td><td>null</td><td>9079940.797368867</td><td>0.0</td><td>26.984566023983696</td><td>2.7630195816278063</td><td>6.147420924603237</td><td>207.15002579764788</td><td>6.533843240611535</td><td>5.76940177494549</td><td>52.39194903214921</td><td>171135.30435094322</td><td>21392.846931779677</td></tr>\n",
       "<tr><td>min</td><td>CA</td><td>02467</td><td>0</td><td>ACTON</td><td>0000025</td><td>\"\"\"LO17 PLZ \"\"\"\"C...</td><td>1.0</td><td>1</td><td>1776</td><td>2</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>35.1</td><td>0.0</td><td>-</td></tr>\n",
       "<tr><td>max</td><td>WA</td><td>98282</td><td>YOUNG AVENUE</td><td>ZEPHYRHILLS</td><td>U-35-28-17-0CH-00...</td><td>WELLINGTON WOODS ...</td><td>2.8E9</td><td>1</td><td>2022</td><td>214</td><td>46</td><td>587</td><td>360.0</td><td>40.125</td><td>287.511</td><td>592158.2647058824</td><td>99974</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------+------------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+------------------+------------------+\n",
       "|summary|  state|              zip5|physical_address|       city|         property_id|       property_type|       sale_price|num_units|        year_built|         num_sales|  zip_num_schools|  city_num_schools|     zip_st_ratio|     city_st_ratio|         CPIHOSNS|              ZVHI|     Median_Income|\n",
       "+-------+-------+------------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+------------------+------------------+\n",
       "|  count|4475884|           4475884|         4475884|    4475884|             4410023|             4475884|          4475884|  4475884|           4309930|           4475884|          4475884|           4475884|          4475884|           4475884|          4475884|           4475884|           3804447|\n",
       "|   mean|   null| 78916.14287523984|             0.0|       null|3.052758767985918E16|                null|659313.0378253771|      1.0|1971.4367920128634| 3.798283646314337|9.988419717758548|120.02769977952958|22.88439441066564|21.869880044100768|185.1464236792117|191442.83962832842| 44238.60159023118|\n",
       "| stddev|   null|25362.334859900817|             0.0|       null|8.301647132342966...|                null|9079940.797368867|      0.0|26.984566023983696|2.7630195816278063|6.147420924603237|207.15002579764788|6.533843240611535|  5.76940177494549|52.39194903214921|171135.30435094322|21392.846931779677|\n",
       "|    min|     CA|             02467|               0|      ACTON|             0000025|\"\"\"LO17 PLZ \"\"\"\"C...|              1.0|        1|              1776|                 2|                0|                 0|              0.0|               0.0|             35.1|               0.0|                 -|\n",
       "|    max|     WA|             98282|    YOUNG AVENUE|ZEPHYRHILLS|U-35-28-17-0CH-00...|WELLINGTON WOODS ...|            2.8E9|        1|              2022|               214|               46|               587|            360.0|            40.125|          287.511| 592158.2647058824|             99974|\n",
       "+-------+-------+------------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+------------------+------------------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_ratings = hospital_ratings.select('Hospital Name', 'Hospital overall rating').dropna()\\\n",
    "    .where(hospital_ratings['Hospital overall rating'] != 'Not Available')\n",
    "\n",
    "#RENAME THE COLUMN FOR JOIN \n",
    "hospital = hospital.withColumn('Hospital Name',hospital.NAME)\n",
    "hospitals_with_ratings =hospital.join(hospital_ratings,['Hospital Name'],'left')\\\n",
    "    .na.fill('0',subset = ['Hospital overall rating'])\n",
    "\n",
    "hospital_final = hospitals_with_ratings\\\n",
    "    .groupBy(['ZIP', 'CITY','STATE','COUNTY','TYPE','Hospital overall rating','OWNER','STATUS'])\\\n",
    "    .count().orderBy('count',ascending = [0])\\\n",
    "    .withColumn('Hospital overall rating', hospitals_with_ratings['Hospital overall rating'].cast('int'))\n",
    "\n",
    "hos1 = hospital_final.groupBy('STATE').agg(F.sum('count'),F.avg('Hospital overall rating'))\\\n",
    "    .orderBy('sum(count)', ascending = [0])\n",
    "hos2 = hospital_final.groupBy('STATE').pivot('TYPE')\\\n",
    "    .agg(F.sum('count').alias(\"CNT\"),F.avg('Hospital overall rating').alias('RATE')).na.fill(0)\n",
    "hos3 = hospital_final.groupBy('STATE').pivot('OWNER')\\\n",
    "    .agg(F.sum('count').alias(\"CNT\"),F.avg('Hospital overall rating').alias('RATE')).na.fill(0)\\\n",
    "    .drop('REHABILITATION_CNT','REHABILITATION_RATE')\n",
    "\n",
    "hos1 = hos1.join(hos2,['STATE'], 'left')\n",
    "hos1 = hos1.join(hos3,['STATE'], 'left')\n",
    "hos1 = hos1.withColumn('STATE', hos1.STATE).drop('null','NOT AVAILABLE').withColumnRenamed('STATE', 'hos_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.join(hos1, df['state'] == hos1['hos_state'], 'left').na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>state</th><th>zip5</th><th>physical_address</th><th>city</th><th>property_id</th><th>property_type</th><th>sale_price</th><th>num_units</th><th>year_built</th><th>num_sales</th><th>zip_num_schools</th><th>city_num_schools</th><th>zip_st_ratio</th><th>city_st_ratio</th><th>CPIHOSNS</th><th>ZVHI</th><th>Median_Income</th><th>hos_state</th><th>sum(count)</th><th>avg(Hospital overall rating)</th><th>CHILDREN_CNT</th><th>CHILDREN_RATE</th><th>CHRONIC DISEASE_CNT</th><th>CHRONIC DISEASE_RATE</th><th>CRITICAL ACCESS_CNT</th><th>CRITICAL ACCESS_RATE</th><th>GENERAL ACUTE CARE_CNT</th><th>GENERAL ACUTE CARE_RATE</th><th>LONG TERM CARE_CNT</th><th>LONG TERM CARE_RATE</th><th>MILITARY_CNT</th><th>MILITARY_RATE</th><th>PSYCHIATRIC_CNT</th><th>PSYCHIATRIC_RATE</th><th>REHABILITATION_CNT</th><th>REHABILITATION_RATE</th><th>SPECIAL_CNT</th><th>SPECIAL_RATE</th><th>WOMEN_CNT</th><th>WOMEN_RATE</th><th>null_CNT</th><th>null_RATE</th><th>GOVERNMENT - DISTRICT/AUTHORITY_CNT</th><th>GOVERNMENT - DISTRICT/AUTHORITY_RATE</th><th>GOVERNMENT - FEDERAL_CNT</th><th>GOVERNMENT - FEDERAL_RATE</th><th>GOVERNMENT - LOCAL_CNT</th><th>GOVERNMENT - LOCAL_RATE</th><th>GOVERNMENT - STATE_CNT</th><th>GOVERNMENT - STATE_RATE</th><th>NON-PROFIT_CNT</th><th>NON-PROFIT_RATE</th><th>NOT AVAILABLE_CNT</th><th>NOT AVAILABLE_RATE</th><th>PROPRIETARY_CNT</th><th>PROPRIETARY_RATE</th></tr>\n",
       "<tr><td>count</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4410023</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4309930</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>3804447</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>78916.14287523984</td><td>0.0</td><td>null</td><td>3.052758767986266...</td><td>null</td><td>659313.0378253771</td><td>1.0</td><td>1971.4367920128634</td><td>3.798283646314337</td><td>9.988419717758548</td><td>120.02769977952958</td><td>22.884394410653794</td><td>21.869880044214035</td><td>185.14642367919774</td><td>191442.8396284907</td><td>44238.60159023118</td><td>null</td><td>513.3634774717128</td><td>0.9281435403014806</td><td>9.72036764134191</td><td>0.113752277762337</td><td>0.0</td><td>0.0</td><td>0.47316686491428284</td><td>0.025413719613508648</td><td>402.013628145859</td><td>1.2037889381030664</td><td>8.54314857132133</td><td>0.0</td><td>16.49976540946995</td><td>0.026250525637194422</td><td>61.50138564806416</td><td>0.002630858642325925</td><td>13.26280104667592</td><td>0.0</td><td>0.4440582016870857</td><td>0.02009279060851443</td><td>0.9051559423792037</td><td>0.0</td><td>0.0</td><td>0.0</td><td>45.06537591233374</td><td>1.3427358904121534</td><td>16.49976540946995</td><td>0.026250525637194422</td><td>34.39919466188132</td><td>0.5741037416975374</td><td>9.984819311671169</td><td>0.0</td><td>252.87892827428055</td><td>1.056729539409112</td><td>16.11915389228139</td><td>0.7197783199638614</td><td>138.4162400097947</td><td>0.8507864485236358</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>25362.334859901526</td><td>0.0</td><td>null</td><td>8.301647132342844...</td><td>null</td><td>9079940.797368908</td><td>0.0</td><td>26.98456602397921</td><td>2.7630195816278116</td><td>6.147420924603054</td><td>207.15002579764544</td><td>6.533843240611339</td><td>5.769401774945538</td><td>52.391949032148155</td><td>171135.30435094197</td><td>21392.846931779804</td><td>null</td><td>121.61247601932722</td><td>0.12441848702916106</td><td>3.031644871003749</td><td>0.3175101881668521</td><td>0.0</td><td>0.0</td><td>2.8167417499602565</td><td>0.1773375985256965</td><td>103.25321379771013</td><td>0.23311443090554923</td><td>4.881975299940025</td><td>0.0</td><td>3.3310024782837653</td><td>0.0732715818846582</td><td>15.622546233698657</td><td>0.017870806635028425</td><td>3.98740238739761</td><td>0.0</td><td>1.1547926141377645</td><td>0.14031776356898332</td><td>0.35501305853499077</td><td>0.0</td><td>0.0</td><td>0.0</td><td>12.071168164781103</td><td>0.27221650288376326</td><td>3.3310024782837653</td><td>0.0732715818846582</td><td>15.227477265122381</td><td>0.298849335411029</td><td>3.642897964969944</td><td>0.0</td><td>64.95621906530774</td><td>0.20044971505184178</td><td>5.344541241584331</td><td>0.32080082710636765</td><td>37.491103939070015</td><td>0.16895652888967266</td></tr>\n",
       "<tr><td>min</td><td>CA</td><td>02467</td><td>0</td><td>ACTON</td><td>0000025</td><td>\"\"\"LO17 PLZ \"\"\"\"C...</td><td>1.0</td><td>1</td><td>1776</td><td>2</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>35.1</td><td>0.0</td><td>-</td><td>CA</td><td>134</td><td>0.7734375</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>62</td><td>0.9830508474576272</td><td>2</td><td>0.0</td><td>6</td><td>0.0</td><td>10</td><td>0.0</td><td>3</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>6</td><td>0.0</td><td>0</td><td>0.0</td><td>2</td><td>0.0</td><td>56</td><td>0.8653846153846154</td><td>0</td><td>0.0</td><td>4</td><td>0.0</td></tr>\n",
       "<tr><td>max</td><td>WA</td><td>98282</td><td>YOUNG AVENUE</td><td>ZEPHYRHILLS</td><td>U-35-28-17-0CH-00...</td><td>WELLINGTON WOODS ...</td><td>2.8E9</td><td>1</td><td>2022</td><td>214</td><td>46</td><td>587</td><td>360.0</td><td>40.125</td><td>287.511</td><td>592158.2647058824</td><td>99974</td><td>WA</td><td>571</td><td>1.2985611510791366</td><td>11</td><td>1.0</td><td>0</td><td>0.0</td><td>40</td><td>1.263157894736842</td><td>453</td><td>1.8941798941798942</td><td>22</td><td>0.0</td><td>18</td><td>0.23076923076923078</td><td>68</td><td>0.125</td><td>22</td><td>0.0</td><td>5</td><td>1.0</td><td>2</td><td>0.0</td><td>0</td><td>0.0</td><td>51</td><td>2.074074074074074</td><td>18</td><td>0.23076923076923078</td><td>42</td><td>1.3333333333333333</td><td>26</td><td>0.0</td><td>285</td><td>1.8421052631578947</td><td>27</td><td>1.5</td><td>165</td><td>1.1823899371069182</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------+------------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------+------------------+----------------------------+-----------------+------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+-------------------+------------------+-------------------+-------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+------------------+-------------------+-----------------+-------------------+------------------+-------------------+\n",
       "|summary|  state|              zip5|physical_address|       city|         property_id|       property_type|       sale_price|num_units|        year_built|         num_sales|  zip_num_schools|  city_num_schools|      zip_st_ratio|     city_st_ratio|          CPIHOSNS|              ZVHI|     Median_Income|hos_state|        sum(count)|avg(Hospital overall rating)|     CHILDREN_CNT|     CHILDREN_RATE|CHRONIC DISEASE_CNT|CHRONIC DISEASE_RATE|CRITICAL ACCESS_CNT|CRITICAL ACCESS_RATE|GENERAL ACUTE CARE_CNT|GENERAL ACUTE CARE_RATE|LONG TERM CARE_CNT|LONG TERM CARE_RATE|      MILITARY_CNT|       MILITARY_RATE|   PSYCHIATRIC_CNT|    PSYCHIATRIC_RATE|REHABILITATION_CNT|REHABILITATION_RATE|       SPECIAL_CNT|       SPECIAL_RATE|          WOMEN_CNT|WOMEN_RATE|null_CNT|null_RATE|GOVERNMENT - DISTRICT/AUTHORITY_CNT|GOVERNMENT - DISTRICT/AUTHORITY_RATE|GOVERNMENT - FEDERAL_CNT|GOVERNMENT - FEDERAL_RATE|GOVERNMENT - LOCAL_CNT|GOVERNMENT - LOCAL_RATE|GOVERNMENT - STATE_CNT|GOVERNMENT - STATE_RATE|    NON-PROFIT_CNT|    NON-PROFIT_RATE|NOT AVAILABLE_CNT| NOT AVAILABLE_RATE|   PROPRIETARY_CNT|   PROPRIETARY_RATE|\n",
       "+-------+-------+------------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------+------------------+----------------------------+-----------------+------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+-------------------+------------------+-------------------+-------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+------------------+-------------------+-----------------+-------------------+------------------+-------------------+\n",
       "|  count|4475884|           4475884|         4475884|    4475884|             4410023|             4475884|          4475884|  4475884|           4309930|           4475884|          4475884|           4475884|           4475884|           4475884|           4475884|           4475884|           3804447|  4475884|           4475884|                     4475884|          4475884|           4475884|            4475884|             4475884|            4475884|             4475884|               4475884|                4475884|           4475884|            4475884|           4475884|             4475884|           4475884|             4475884|           4475884|            4475884|           4475884|            4475884|            4475884|   4475884| 4475884|  4475884|                            4475884|                             4475884|                 4475884|                  4475884|               4475884|                4475884|               4475884|                4475884|           4475884|            4475884|          4475884|            4475884|           4475884|            4475884|\n",
       "|   mean|   null| 78916.14287523984|             0.0|       null|3.052758767986266...|                null|659313.0378253771|      1.0|1971.4367920128634| 3.798283646314337|9.988419717758548|120.02769977952958|22.884394410653794|21.869880044214035|185.14642367919774| 191442.8396284907| 44238.60159023118|     null| 513.3634774717128|          0.9281435403014806| 9.72036764134191| 0.113752277762337|                0.0|                 0.0|0.47316686491428284|0.025413719613508648|      402.013628145859|     1.2037889381030664|  8.54314857132133|                0.0| 16.49976540946995|0.026250525637194422| 61.50138564806416|0.002630858642325925| 13.26280104667592|                0.0|0.4440582016870857|0.02009279060851443| 0.9051559423792037|       0.0|     0.0|      0.0|                  45.06537591233374|                  1.3427358904121534|       16.49976540946995|     0.026250525637194422|     34.39919466188132|     0.5741037416975374|     9.984819311671169|                    0.0|252.87892827428055|  1.056729539409112|16.11915389228139| 0.7197783199638614| 138.4162400097947| 0.8507864485236358|\n",
       "| stddev|   null|25362.334859901526|             0.0|       null|8.301647132342844...|                null|9079940.797368908|      0.0| 26.98456602397921|2.7630195816278116|6.147420924603054|207.15002579764544| 6.533843240611339| 5.769401774945538|52.391949032148155|171135.30435094197|21392.846931779804|     null|121.61247601932722|         0.12441848702916106|3.031644871003749|0.3175101881668521|                0.0|                 0.0| 2.8167417499602565|  0.1773375985256965|    103.25321379771013|    0.23311443090554923| 4.881975299940025|                0.0|3.3310024782837653|  0.0732715818846582|15.622546233698657|0.017870806635028425|  3.98740238739761|                0.0|1.1547926141377645|0.14031776356898332|0.35501305853499077|       0.0|     0.0|      0.0|                 12.071168164781103|                 0.27221650288376326|      3.3310024782837653|       0.0732715818846582|    15.227477265122381|      0.298849335411029|     3.642897964969944|                    0.0| 64.95621906530774|0.20044971505184178|5.344541241584331|0.32080082710636765|37.491103939070015|0.16895652888967266|\n",
       "|    min|     CA|             02467|               0|      ACTON|             0000025|\"\"\"LO17 PLZ \"\"\"\"C...|              1.0|        1|              1776|                 2|                0|                 0|               0.0|               0.0|              35.1|               0.0|                 -|       CA|               134|                   0.7734375|                0|               0.0|                  0|                 0.0|                  0|                 0.0|                    62|     0.9830508474576272|                 2|                0.0|                 6|                 0.0|                10|                 0.0|                 3|                0.0|                 0|                0.0|                  0|       0.0|       0|      0.0|                                  0|                                 0.0|                       6|                      0.0|                     0|                    0.0|                     2|                    0.0|                56| 0.8653846153846154|                0|                0.0|                 4|                0.0|\n",
       "|    max|     WA|             98282|    YOUNG AVENUE|ZEPHYRHILLS|U-35-28-17-0CH-00...|WELLINGTON WOODS ...|            2.8E9|        1|              2022|               214|               46|               587|             360.0|            40.125|           287.511| 592158.2647058824|             99974|       WA|               571|          1.2985611510791366|               11|               1.0|                  0|                 0.0|                 40|   1.263157894736842|                   453|     1.8941798941798942|                22|                0.0|                18| 0.23076923076923078|                68|               0.125|                22|                0.0|                 5|                1.0|                  2|       0.0|       0|      0.0|                                 51|                   2.074074074074074|                      18|      0.23076923076923078|                    42|     1.3333333333333333|                    26|                    0.0|               285| 1.8421052631578947|               27|                1.5|               165| 1.1823899371069182|\n",
       "+-------+-------+------------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------+------------------+----------------------------+-----------------+------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+-------------------+------------------+-------------------+-------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+------------------+-------------------+-----------------+-------------------+------------------+-------------------+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create state column\n",
    "state = crime.withColumn('ColCommasRemoved',F.split(crime.county_name,','))\\\n",
    "    .select('county_name',F.rtrim(F.col('ColCommasRemoved')[1]))\n",
    "state = state.withColumn('state',state['rtrim(ColCommasRemoved[1])']).drop('rtrim(ColCommasRemoved[1])')\n",
    "crime = crime.join(state, 'county_name','left')\n",
    "\n",
    "# join with zillow data\n",
    "CountyCrossWalk_Zillow = CountyCrossWalk_Zillow.withColumn('FIPS_ST',CountyCrossWalk_Zillow['StateFIPS'])\\\n",
    "    .withColumn('FIPS_CTY',CountyCrossWalk_Zillow['CountyFIPS'])\n",
    "crime = crime.join(CountyCrossWalk_Zillow,['FIPS_ST','FIPS_CTY'],'left')\n",
    "\n",
    "crime = crime.select(['CountyName','state','crime_rate_per_100000'\n",
    "        ,'MURDER','RAPE','ROBBERY','AGASSLT','BURGLRY','LARCENY','MVTHEFT','ARSON','population']).dropna()\n",
    "crime = crime.groupBy('state').agg(F.count('MURDER'),F.count('RAPE'),F.count('ROBBERY')\n",
    "    ,F.count('AGASSLT'),F.count('BURGLRY'),F.count('MVTHEFT'),F.count('ARSON')\n",
    "    ,F.sum('population')\n",
    "    ,F.avg('crime_rate_per_100000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(crime,'state','left').na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>state</th><th>zip5</th><th>physical_address</th><th>city</th><th>property_id</th><th>property_type</th><th>sale_price</th><th>num_units</th><th>year_built</th><th>num_sales</th><th>zip_num_schools</th><th>city_num_schools</th><th>zip_st_ratio</th><th>city_st_ratio</th><th>CPIHOSNS</th><th>ZVHI</th><th>Median_Income</th><th>hos_state</th><th>sum(count)</th><th>avg(Hospital overall rating)</th><th>CHILDREN_CNT</th><th>CHILDREN_RATE</th><th>CHRONIC DISEASE_CNT</th><th>CHRONIC DISEASE_RATE</th><th>CRITICAL ACCESS_CNT</th><th>CRITICAL ACCESS_RATE</th><th>GENERAL ACUTE CARE_CNT</th><th>GENERAL ACUTE CARE_RATE</th><th>LONG TERM CARE_CNT</th><th>LONG TERM CARE_RATE</th><th>MILITARY_CNT</th><th>MILITARY_RATE</th><th>PSYCHIATRIC_CNT</th><th>PSYCHIATRIC_RATE</th><th>REHABILITATION_CNT</th><th>REHABILITATION_RATE</th><th>SPECIAL_CNT</th><th>SPECIAL_RATE</th><th>WOMEN_CNT</th><th>WOMEN_RATE</th><th>null_CNT</th><th>null_RATE</th><th>GOVERNMENT - DISTRICT/AUTHORITY_CNT</th><th>GOVERNMENT - DISTRICT/AUTHORITY_RATE</th><th>GOVERNMENT - FEDERAL_CNT</th><th>GOVERNMENT - FEDERAL_RATE</th><th>GOVERNMENT - LOCAL_CNT</th><th>GOVERNMENT - LOCAL_RATE</th><th>GOVERNMENT - STATE_CNT</th><th>GOVERNMENT - STATE_RATE</th><th>NON-PROFIT_CNT</th><th>NON-PROFIT_RATE</th><th>NOT AVAILABLE_CNT</th><th>NOT AVAILABLE_RATE</th><th>PROPRIETARY_CNT</th><th>PROPRIETARY_RATE</th><th>count(MURDER)</th><th>count(RAPE)</th><th>count(ROBBERY)</th><th>count(AGASSLT)</th><th>count(BURGLRY)</th><th>count(MVTHEFT)</th><th>count(ARSON)</th><th>sum(population)</th><th>avg(crime_rate_per_100000)</th></tr>\n",
       "<tr><td>count</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4410023</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4309930</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>3804447</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td><td>4475884</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>78916.14287523984</td><td>0.0</td><td>null</td><td>3.052758767986070...</td><td>null</td><td>659313.0378253771</td><td>1.0</td><td>1971.4367920128634</td><td>3.798283646314337</td><td>9.988419717758548</td><td>120.02769977952958</td><td>22.884394410656185</td><td>21.86988004422112</td><td>185.14642367919225</td><td>191442.83962850826</td><td>44238.60159023118</td><td>null</td><td>513.3634774717128</td><td>0.9281435403014806</td><td>9.72036764134191</td><td>0.113752277762337</td><td>0.0</td><td>0.0</td><td>0.47316686491428284</td><td>0.025413719613508648</td><td>402.013628145859</td><td>1.2037889381030662</td><td>8.54314857132133</td><td>0.0</td><td>16.49976540946995</td><td>0.026250525637194422</td><td>61.50138564806416</td><td>0.002630858642325925</td><td>13.26280104667592</td><td>0.0</td><td>0.4440582016870857</td><td>0.02009279060851443</td><td>0.9051559423792037</td><td>0.0</td><td>0.0</td><td>0.0</td><td>45.06537591233374</td><td>1.3427358904121531</td><td>16.49976540946995</td><td>0.026250525637194422</td><td>34.39919466188132</td><td>0.5741037416975374</td><td>9.984819311671169</td><td>0.0</td><td>252.87892827428055</td><td>1.0567295394091123</td><td>16.11915389228139</td><td>0.7197783199638614</td><td>138.4162400097947</td><td>0.8507864485236358</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>25362.33485990081</td><td>0.0</td><td>null</td><td>8.301647132342892...</td><td>null</td><td>9079940.797369113</td><td>0.0</td><td>26.984566023979863</td><td>2.763019581627796</td><td>6.147420924603444</td><td>207.15002579763726</td><td>6.5338432406116285</td><td>5.769401774945314</td><td>52.391949032147785</td><td>171135.30435094365</td><td>21392.8469317793</td><td>null</td><td>121.61247601932723</td><td>0.12441848702916104</td><td>3.0316448710037487</td><td>0.3175101881668521</td><td>0.0</td><td>0.0</td><td>2.8167417499602565</td><td>0.17733759852569647</td><td>103.25321379771013</td><td>0.23311443090554923</td><td>4.8819752999400245</td><td>0.0</td><td>3.3310024782837653</td><td>0.07327158188465818</td><td>15.622546233698657</td><td>0.01787080663502843</td><td>3.98740238739761</td><td>0.0</td><td>1.1547926141377645</td><td>0.14031776356898332</td><td>0.35501305853499077</td><td>0.0</td><td>0.0</td><td>0.0</td><td>12.071168164781103</td><td>0.2722165028837633</td><td>3.3310024782837653</td><td>0.07327158188465818</td><td>15.227477265122378</td><td>0.2988493354110289</td><td>3.642897964969944</td><td>0.0</td><td>64.95621906530772</td><td>0.20044971505184178</td><td>5.344541241584331</td><td>0.3208008271063677</td><td>37.491103939070015</td><td>0.16895652888967266</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>min</td><td>CA</td><td>02467</td><td>0</td><td>ACTON</td><td>0000025</td><td>\"\"\"LO17 PLZ \"\"\"\"C...</td><td>1.0</td><td>1</td><td>1776</td><td>2</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>35.1</td><td>0.0</td><td>-</td><td>CA</td><td>134</td><td>0.7734375</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>62</td><td>0.9830508474576272</td><td>2</td><td>0.0</td><td>6</td><td>0.0</td><td>10</td><td>0.0</td><td>3</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>6</td><td>0.0</td><td>0</td><td>0.0</td><td>2</td><td>0.0</td><td>56</td><td>0.8653846153846154</td><td>0</td><td>0.0</td><td>4</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>max</td><td>WA</td><td>98282</td><td>YOUNG AVENUE</td><td>ZEPHYRHILLS</td><td>U-35-28-17-0CH-00...</td><td>WELLINGTON WOODS ...</td><td>2.8E9</td><td>1</td><td>2022</td><td>214</td><td>46</td><td>587</td><td>360.0</td><td>40.125</td><td>287.511</td><td>592158.2647058824</td><td>99974</td><td>WA</td><td>571</td><td>1.2985611510791366</td><td>11</td><td>1.0</td><td>0</td><td>0.0</td><td>40</td><td>1.263157894736842</td><td>453</td><td>1.8941798941798942</td><td>22</td><td>0.0</td><td>18</td><td>0.23076923076923078</td><td>68</td><td>0.125</td><td>22</td><td>0.0</td><td>5</td><td>1.0</td><td>2</td><td>0.0</td><td>0</td><td>0.0</td><td>51</td><td>2.074074074074074</td><td>18</td><td>0.23076923076923078</td><td>42</td><td>1.3333333333333333</td><td>26</td><td>0.0</td><td>285</td><td>1.8421052631578947</td><td>27</td><td>1.5</td><td>165</td><td>1.1823899371069182</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------+-----------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-----------------+---------+------------------+----------------------------+------------------+------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+-------------------+------------------+-------------------+-------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+------------------+-------------------+-----------------+------------------+------------------+-------------------+-------------+-----------+--------------+--------------+--------------+--------------+------------+---------------+--------------------------+\n",
       "|summary|  state|             zip5|physical_address|       city|         property_id|       property_type|       sale_price|num_units|        year_built|        num_sales|  zip_num_schools|  city_num_schools|      zip_st_ratio|    city_st_ratio|          CPIHOSNS|              ZVHI|    Median_Income|hos_state|        sum(count)|avg(Hospital overall rating)|      CHILDREN_CNT|     CHILDREN_RATE|CHRONIC DISEASE_CNT|CHRONIC DISEASE_RATE|CRITICAL ACCESS_CNT|CRITICAL ACCESS_RATE|GENERAL ACUTE CARE_CNT|GENERAL ACUTE CARE_RATE|LONG TERM CARE_CNT|LONG TERM CARE_RATE|      MILITARY_CNT|       MILITARY_RATE|   PSYCHIATRIC_CNT|    PSYCHIATRIC_RATE|REHABILITATION_CNT|REHABILITATION_RATE|       SPECIAL_CNT|       SPECIAL_RATE|          WOMEN_CNT|WOMEN_RATE|null_CNT|null_RATE|GOVERNMENT - DISTRICT/AUTHORITY_CNT|GOVERNMENT - DISTRICT/AUTHORITY_RATE|GOVERNMENT - FEDERAL_CNT|GOVERNMENT - FEDERAL_RATE|GOVERNMENT - LOCAL_CNT|GOVERNMENT - LOCAL_RATE|GOVERNMENT - STATE_CNT|GOVERNMENT - STATE_RATE|    NON-PROFIT_CNT|    NON-PROFIT_RATE|NOT AVAILABLE_CNT|NOT AVAILABLE_RATE|   PROPRIETARY_CNT|   PROPRIETARY_RATE|count(MURDER)|count(RAPE)|count(ROBBERY)|count(AGASSLT)|count(BURGLRY)|count(MVTHEFT)|count(ARSON)|sum(population)|avg(crime_rate_per_100000)|\n",
       "+-------+-------+-----------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-----------------+---------+------------------+----------------------------+------------------+------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+-------------------+------------------+-------------------+-------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+------------------+-------------------+-----------------+------------------+------------------+-------------------+-------------+-----------+--------------+--------------+--------------+--------------+------------+---------------+--------------------------+\n",
       "|  count|4475884|          4475884|         4475884|    4475884|             4410023|             4475884|          4475884|  4475884|           4309930|          4475884|          4475884|           4475884|           4475884|          4475884|           4475884|           4475884|          3804447|  4475884|           4475884|                     4475884|           4475884|           4475884|            4475884|             4475884|            4475884|             4475884|               4475884|                4475884|           4475884|            4475884|           4475884|             4475884|           4475884|             4475884|           4475884|            4475884|           4475884|            4475884|            4475884|   4475884| 4475884|  4475884|                            4475884|                             4475884|                 4475884|                  4475884|               4475884|                4475884|               4475884|                4475884|           4475884|            4475884|          4475884|           4475884|           4475884|            4475884|      4475884|    4475884|       4475884|       4475884|       4475884|       4475884|     4475884|        4475884|                   4475884|\n",
       "|   mean|   null|78916.14287523984|             0.0|       null|3.052758767986070...|                null|659313.0378253771|      1.0|1971.4367920128634|3.798283646314337|9.988419717758548|120.02769977952958|22.884394410656185|21.86988004422112|185.14642367919225|191442.83962850826|44238.60159023118|     null| 513.3634774717128|          0.9281435403014806|  9.72036764134191| 0.113752277762337|                0.0|                 0.0|0.47316686491428284|0.025413719613508648|      402.013628145859|     1.2037889381030662|  8.54314857132133|                0.0| 16.49976540946995|0.026250525637194422| 61.50138564806416|0.002630858642325925| 13.26280104667592|                0.0|0.4440582016870857|0.02009279060851443| 0.9051559423792037|       0.0|     0.0|      0.0|                  45.06537591233374|                  1.3427358904121531|       16.49976540946995|     0.026250525637194422|     34.39919466188132|     0.5741037416975374|     9.984819311671169|                    0.0|252.87892827428055| 1.0567295394091123|16.11915389228139|0.7197783199638614| 138.4162400097947| 0.8507864485236358|          0.0|        0.0|           0.0|           0.0|           0.0|           0.0|         0.0|            0.0|                       0.0|\n",
       "| stddev|   null|25362.33485990081|             0.0|       null|8.301647132342892...|                null|9079940.797369113|      0.0|26.984566023979863|2.763019581627796|6.147420924603444|207.15002579763726|6.5338432406116285|5.769401774945314|52.391949032147785|171135.30435094365| 21392.8469317793|     null|121.61247601932723|         0.12441848702916104|3.0316448710037487|0.3175101881668521|                0.0|                 0.0| 2.8167417499602565| 0.17733759852569647|    103.25321379771013|    0.23311443090554923|4.8819752999400245|                0.0|3.3310024782837653| 0.07327158188465818|15.622546233698657| 0.01787080663502843|  3.98740238739761|                0.0|1.1547926141377645|0.14031776356898332|0.35501305853499077|       0.0|     0.0|      0.0|                 12.071168164781103|                  0.2722165028837633|      3.3310024782837653|      0.07327158188465818|    15.227477265122378|     0.2988493354110289|     3.642897964969944|                    0.0| 64.95621906530772|0.20044971505184178|5.344541241584331|0.3208008271063677|37.491103939070015|0.16895652888967266|          0.0|        0.0|           0.0|           0.0|           0.0|           0.0|         0.0|            0.0|                       0.0|\n",
       "|    min|     CA|            02467|               0|      ACTON|             0000025|\"\"\"LO17 PLZ \"\"\"\"C...|              1.0|        1|              1776|                2|                0|                 0|               0.0|              0.0|              35.1|               0.0|                -|       CA|               134|                   0.7734375|                 0|               0.0|                  0|                 0.0|                  0|                 0.0|                    62|     0.9830508474576272|                 2|                0.0|                 6|                 0.0|                10|                 0.0|                 3|                0.0|                 0|                0.0|                  0|       0.0|       0|      0.0|                                  0|                                 0.0|                       6|                      0.0|                     0|                    0.0|                     2|                    0.0|                56| 0.8653846153846154|                0|               0.0|                 4|                0.0|            0|          0|             0|             0|             0|             0|           0|            0.0|                       0.0|\n",
       "|    max|     WA|            98282|    YOUNG AVENUE|ZEPHYRHILLS|U-35-28-17-0CH-00...|WELLINGTON WOODS ...|            2.8E9|        1|              2022|              214|               46|               587|             360.0|           40.125|           287.511| 592158.2647058824|            99974|       WA|               571|          1.2985611510791366|                11|               1.0|                  0|                 0.0|                 40|   1.263157894736842|                   453|     1.8941798941798942|                22|                0.0|                18| 0.23076923076923078|                68|               0.125|                22|                0.0|                 5|                1.0|                  2|       0.0|       0|      0.0|                                 51|                   2.074074074074074|                      18|      0.23076923076923078|                    42|     1.3333333333333333|                    26|                    0.0|               285| 1.8421052631578947|               27|               1.5|               165| 1.1823899371069182|            0|          0|             0|             0|             0|             0|           0|            0.0|                       0.0|\n",
       "+-------+-------+-----------------+----------------+-----------+--------------------+--------------------+-----------------+---------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-----------------+---------+------------------+----------------------------+------------------+------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+--------------------+------------------+--------------------+------------------+-------------------+------------------+-------------------+-------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+------------------+-------------------+-----------------+------------------+------------------+-------------------+-------------+-----------+--------------+--------------+--------------+--------------+------------+---------------+--------------------------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create historical sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add purchase ranking to df\n",
    "df = df.withColumn(\"rank\", dense_rank().\\\n",
    "    over(Window.partitionBy('city','state', 'physical_address', 'zip5', 'property_type').\\\n",
    "    orderBy('sale_date')))\n",
    "\n",
    "#find previous purchase\n",
    "ranked = df.select('city','state', 'physical_address', 'zip5', 'property_type','sale_date', 'sale_price').withColumn(\"rank\", dense_rank().\\\n",
    "    over(Window.partitionBy('city','state', 'physical_address', 'zip5', 'property_type').\\\n",
    "    orderBy('sale_date')))\n",
    "ranked = ranked.withColumn(\"rank\", col('rank') + 1)\n",
    "ranked = ranked.withColumnRenamed('sale_date', 'prev_sale_date').withColumnRenamed('sale_price', 'prev_sale_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(ranked,['city','state', 'physical_address', 'zip5', 'property_type', 'rank'],'left').na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>city</th><th>state</th><th>physical_address</th><th>zip5</th><th>property_type</th><th>rank</th><th>property_id</th><th>sale_price</th><th>num_units</th><th>year_built</th><th>num_sales</th><th>zip_num_schools</th><th>city_num_schools</th><th>zip_st_ratio</th><th>city_st_ratio</th><th>CPIHOSNS</th><th>ZVHI</th><th>Median_Income</th><th>hos_state</th><th>sum(count)</th><th>avg(Hospital overall rating)</th><th>CHILDREN_CNT</th><th>CHILDREN_RATE</th><th>CHRONIC DISEASE_CNT</th><th>CHRONIC DISEASE_RATE</th><th>CRITICAL ACCESS_CNT</th><th>CRITICAL ACCESS_RATE</th><th>GENERAL ACUTE CARE_CNT</th><th>GENERAL ACUTE CARE_RATE</th><th>LONG TERM CARE_CNT</th><th>LONG TERM CARE_RATE</th><th>MILITARY_CNT</th><th>MILITARY_RATE</th><th>PSYCHIATRIC_CNT</th><th>PSYCHIATRIC_RATE</th><th>REHABILITATION_CNT</th><th>REHABILITATION_RATE</th><th>SPECIAL_CNT</th><th>SPECIAL_RATE</th><th>WOMEN_CNT</th><th>WOMEN_RATE</th><th>null_CNT</th><th>null_RATE</th><th>GOVERNMENT - DISTRICT/AUTHORITY_CNT</th><th>GOVERNMENT - DISTRICT/AUTHORITY_RATE</th><th>GOVERNMENT - FEDERAL_CNT</th><th>GOVERNMENT - FEDERAL_RATE</th><th>GOVERNMENT - LOCAL_CNT</th><th>GOVERNMENT - LOCAL_RATE</th><th>GOVERNMENT - STATE_CNT</th><th>GOVERNMENT - STATE_RATE</th><th>NON-PROFIT_CNT</th><th>NON-PROFIT_RATE</th><th>NOT AVAILABLE_CNT</th><th>NOT AVAILABLE_RATE</th><th>PROPRIETARY_CNT</th><th>PROPRIETARY_RATE</th><th>count(MURDER)</th><th>count(RAPE)</th><th>count(ROBBERY)</th><th>count(AGASSLT)</th><th>count(BURGLRY)</th><th>count(MVTHEFT)</th><th>count(ARSON)</th><th>sum(population)</th><th>avg(crime_rate_per_100000)</th><th>prev_sale_price</th></tr>\n",
       "<tr><td>count</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4429454</td><td>4495744</td><td>4495744</td><td>4329731</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>3809908</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td><td>4495744</td></tr>\n",
       "<tr><td>mean</td><td>null</td><td>null</td><td>0.0</td><td>78715.09374777567</td><td>null</td><td>2.3341102162400706</td><td>3.152302631300765...</td><td>657133.0282649546</td><td>1.0</td><td>1971.4249742074046</td><td>3.8197230536258293</td><td>9.97939517908493</td><td>119.63939472532243</td><td>22.85417420154577</td><td>21.842681405718626</td><td>185.22427818843906</td><td>191218.26730470825</td><td>44242.33275819979</td><td>null</td><td>512.7071018723486</td><td>0.929555430723759</td><td>9.711722242191726</td><td>0.11748978589528229</td><td>0.0</td><td>0.0</td><td>0.4738830769723543</td><td>0.025456343550406123</td><td>401.3237906784728</td><td>1.2065084902330472</td><td>8.599538140961762</td><td>0.0</td><td>16.484022221905875</td><td>0.02711302751429654</td><td>61.45890913717507</td><td>0.002633222243848...</td><td>13.298413566252883</td><td>0.0</td><td>0.45538891894200384</td><td>0.0201159140733992</td><td>0.9014338894741337</td><td>0.0</td><td>0.0</td><td>0.0</td><td>44.983007039546735</td><td>1.3458546882727174</td><td>16.484022221905875</td><td>0.02711302751429654</td><td>34.24986186935911</td><td>0.5717980369847105</td><td>9.964977320772713</td><td>0.0</td><td>252.3552566605216</td><td>1.059063090144617</td><td>16.16354000583663</td><td>0.7167772179608339</td><td>138.50643675440594</td><td>0.8520851247306207</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>428270.20661118603</td></tr>\n",
       "<tr><td>stddev</td><td>null</td><td>null</td><td>0.0</td><td>25487.820339050708</td><td>null</td><td>1.6753192617850934</td><td>8.416362845689014...</td><td>9060270.952274637</td><td>0.0</td><td>26.967715035431745</td><td>2.9007030201841197</td><td>6.145088202804623</td><td>206.782162377122</td><td>6.570097807498317</td><td>5.7747557048513665</td><td>52.35879100252017</td><td>170867.19585717705</td><td>21383.63395214622</td><td>null</td><td>121.75794339179518</td><td>0.12600247528086944</td><td>3.0287556444564676</td><td>0.3220030421730513</td><td>0.0</td><td>0.0</td><td>2.821837343777682</td><td>0.17747522058636103</td><td>103.55072961648402</td><td>0.23630465029746514</td><td>4.9493076698276335</td><td>0.0</td><td>3.332438910131705</td><td>0.07430839434762729</td><td>15.60597609555769</td><td>0.017879040568963018</td><td>4.020364918716661</td><td>0.0</td><td>1.1651449071351825</td><td>0.14039682495989497</td><td>0.3592807944222246</td><td>0.0</td><td>0.0</td><td>0.0</td><td>12.110037339564219</td><td>0.2757476369159617</td><td>3.332438910131705</td><td>0.07430839434762729</td><td>15.359712078238921</td><td>0.3006706473465652</td><td>3.653705749731558</td><td>0.0</td><td>65.2940637666894</td><td>0.2031716149486637</td><td>5.3812161337138225</td><td>0.32355553893756256</td><td>37.48648702430493</td><td>0.170202147996976</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>6861719.152129494</td></tr>\n",
       "<tr><td>min</td><td>ACTON</td><td>CA</td><td>0</td><td>02467</td><td>\"\"\"LO17 PLZ \"\"\"\"C...</td><td>1</td><td>0000025</td><td>1.0</td><td>1</td><td>1776</td><td>2</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>35.1</td><td>0.0</td><td>-</td><td>CA</td><td>134</td><td>0.7734375</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>62</td><td>0.9830508474576272</td><td>2</td><td>0.0</td><td>6</td><td>0.0</td><td>10</td><td>0.0</td><td>3</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>6</td><td>0.0</td><td>0</td><td>0.0</td><td>2</td><td>0.0</td><td>56</td><td>0.8653846153846154</td><td>0</td><td>0.0</td><td>4</td><td>0.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "<tr><td>max</td><td>ZEPHYRHILLS</td><td>WA</td><td>YOUNG AVENUE</td><td>98282</td><td>WELLINGTON WOODS ...</td><td>106</td><td>U-35-28-17-0CH-00...</td><td>2.8E9</td><td>1</td><td>2022</td><td>214</td><td>46</td><td>587</td><td>360.0</td><td>40.125</td><td>287.511</td><td>592158.2647058824</td><td>99974</td><td>WA</td><td>571</td><td>1.2985611510791366</td><td>11</td><td>1.0</td><td>0</td><td>0.0</td><td>40</td><td>1.263157894736842</td><td>453</td><td>1.8941798941798942</td><td>22</td><td>0.0</td><td>18</td><td>0.23076923076923078</td><td>68</td><td>0.125</td><td>22</td><td>0.0</td><td>5</td><td>1.0</td><td>2</td><td>0.0</td><td>0</td><td>0.0</td><td>51</td><td>2.074074074074074</td><td>18</td><td>0.23076923076923078</td><td>42</td><td>1.3333333333333333</td><td>26</td><td>0.0</td><td>285</td><td>1.8421052631578947</td><td>27</td><td>1.5</td><td>165</td><td>1.1823899371069182</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>1.92001088E9</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-----------+-------+----------------+------------------+--------------------+------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+-----------------+---------+------------------+----------------------------+------------------+-------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+-------------------+-----------------+--------------------+------------------+-------------------+-------------------+-------------------+------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+-------------+-----------+--------------+--------------+--------------+--------------+------------+---------------+--------------------------+------------------+\n",
       "|summary|       city|  state|physical_address|              zip5|       property_type|              rank|         property_id|       sale_price|num_units|        year_built|         num_sales|  zip_num_schools|  city_num_schools|     zip_st_ratio|     city_st_ratio|          CPIHOSNS|              ZVHI|    Median_Income|hos_state|        sum(count)|avg(Hospital overall rating)|      CHILDREN_CNT|      CHILDREN_RATE|CHRONIC DISEASE_CNT|CHRONIC DISEASE_RATE|CRITICAL ACCESS_CNT|CRITICAL ACCESS_RATE|GENERAL ACUTE CARE_CNT|GENERAL ACUTE CARE_RATE|LONG TERM CARE_CNT|LONG TERM CARE_RATE|      MILITARY_CNT|      MILITARY_RATE|  PSYCHIATRIC_CNT|    PSYCHIATRIC_RATE|REHABILITATION_CNT|REHABILITATION_RATE|        SPECIAL_CNT|       SPECIAL_RATE|         WOMEN_CNT|WOMEN_RATE|null_CNT|null_RATE|GOVERNMENT - DISTRICT/AUTHORITY_CNT|GOVERNMENT - DISTRICT/AUTHORITY_RATE|GOVERNMENT - FEDERAL_CNT|GOVERNMENT - FEDERAL_RATE|GOVERNMENT - LOCAL_CNT|GOVERNMENT - LOCAL_RATE|GOVERNMENT - STATE_CNT|GOVERNMENT - STATE_RATE|   NON-PROFIT_CNT|   NON-PROFIT_RATE| NOT AVAILABLE_CNT| NOT AVAILABLE_RATE|   PROPRIETARY_CNT|  PROPRIETARY_RATE|count(MURDER)|count(RAPE)|count(ROBBERY)|count(AGASSLT)|count(BURGLRY)|count(MVTHEFT)|count(ARSON)|sum(population)|avg(crime_rate_per_100000)|   prev_sale_price|\n",
       "+-------+-----------+-------+----------------+------------------+--------------------+------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+-----------------+---------+------------------+----------------------------+------------------+-------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+-------------------+-----------------+--------------------+------------------+-------------------+-------------------+-------------------+------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+-------------+-----------+--------------+--------------+--------------+--------------+------------+---------------+--------------------------+------------------+\n",
       "|  count|    4495744|4495744|         4495744|           4495744|             4495744|           4495744|             4429454|          4495744|  4495744|           4329731|           4495744|          4495744|           4495744|          4495744|           4495744|           4495744|           4495744|          3809908|  4495744|           4495744|                     4495744|           4495744|            4495744|            4495744|             4495744|            4495744|             4495744|               4495744|                4495744|           4495744|            4495744|           4495744|            4495744|          4495744|             4495744|           4495744|            4495744|            4495744|            4495744|           4495744|   4495744| 4495744|  4495744|                            4495744|                             4495744|                 4495744|                  4495744|               4495744|                4495744|               4495744|                4495744|          4495744|           4495744|           4495744|            4495744|           4495744|           4495744|      4495744|    4495744|       4495744|       4495744|       4495744|       4495744|     4495744|        4495744|                   4495744|           4495744|\n",
       "|   mean|       null|   null|             0.0| 78715.09374777567|                null|2.3341102162400706|3.152302631300765...|657133.0282649546|      1.0|1971.4249742074046|3.8197230536258293| 9.97939517908493|119.63939472532243|22.85417420154577|21.842681405718626|185.22427818843906|191218.26730470825|44242.33275819979|     null| 512.7071018723486|           0.929555430723759| 9.711722242191726|0.11748978589528229|                0.0|                 0.0| 0.4738830769723543|0.025456343550406123|     401.3237906784728|     1.2065084902330472| 8.599538140961762|                0.0|16.484022221905875|0.02711302751429654|61.45890913717507|0.002633222243848...|13.298413566252883|                0.0|0.45538891894200384| 0.0201159140733992|0.9014338894741337|       0.0|     0.0|      0.0|                 44.983007039546735|                  1.3458546882727174|      16.484022221905875|      0.02711302751429654|     34.24986186935911|     0.5717980369847105|     9.964977320772713|                    0.0|252.3552566605216| 1.059063090144617| 16.16354000583663| 0.7167772179608339|138.50643675440594|0.8520851247306207|          0.0|        0.0|           0.0|           0.0|           0.0|           0.0|         0.0|            0.0|                       0.0|428270.20661118603|\n",
       "| stddev|       null|   null|             0.0|25487.820339050708|                null|1.6753192617850934|8.416362845689014...|9060270.952274637|      0.0|26.967715035431745|2.9007030201841197|6.145088202804623|  206.782162377122|6.570097807498317|5.7747557048513665| 52.35879100252017|170867.19585717705|21383.63395214622|     null|121.75794339179518|         0.12600247528086944|3.0287556444564676| 0.3220030421730513|                0.0|                 0.0|  2.821837343777682| 0.17747522058636103|    103.55072961648402|    0.23630465029746514|4.9493076698276335|                0.0| 3.332438910131705|0.07430839434762729|15.60597609555769|0.017879040568963018| 4.020364918716661|                0.0| 1.1651449071351825|0.14039682495989497|0.3592807944222246|       0.0|     0.0|      0.0|                 12.110037339564219|                  0.2757476369159617|       3.332438910131705|      0.07430839434762729|    15.359712078238921|     0.3006706473465652|     3.653705749731558|                    0.0| 65.2940637666894|0.2031716149486637|5.3812161337138225|0.32355553893756256| 37.48648702430493| 0.170202147996976|          0.0|        0.0|           0.0|           0.0|           0.0|           0.0|         0.0|            0.0|                       0.0| 6861719.152129494|\n",
       "|    min|      ACTON|     CA|               0|             02467|\"\"\"LO17 PLZ \"\"\"\"C...|                 1|             0000025|              1.0|        1|              1776|                 2|                0|                 0|              0.0|               0.0|              35.1|               0.0|                -|       CA|               134|                   0.7734375|                 0|                0.0|                  0|                 0.0|                  0|                 0.0|                    62|     0.9830508474576272|                 2|                0.0|                 6|                0.0|               10|                 0.0|                 3|                0.0|                  0|                0.0|                 0|       0.0|       0|      0.0|                                  0|                                 0.0|                       6|                      0.0|                     0|                    0.0|                     2|                    0.0|               56|0.8653846153846154|                 0|                0.0|                 4|               0.0|            0|          0|             0|             0|             0|             0|           0|            0.0|                       0.0|               0.0|\n",
       "|    max|ZEPHYRHILLS|     WA|    YOUNG AVENUE|             98282|WELLINGTON WOODS ...|               106|U-35-28-17-0CH-00...|            2.8E9|        1|              2022|               214|               46|               587|            360.0|            40.125|           287.511| 592158.2647058824|            99974|       WA|               571|          1.2985611510791366|                11|                1.0|                  0|                 0.0|                 40|   1.263157894736842|                   453|     1.8941798941798942|                22|                0.0|                18|0.23076923076923078|               68|               0.125|                22|                0.0|                  5|                1.0|                 2|       0.0|       0|      0.0|                                 51|                   2.074074074074074|                      18|      0.23076923076923078|                    42|     1.3333333333333333|                    26|                    0.0|              285|1.8421052631578947|                27|                1.5|               165|1.1823899371069182|            0|          0|             0|             0|             0|             0|           0|            0.0|                       0.0|      1.92001088E9|\n",
       "+-------+-----------+-------+----------------+------------------+--------------------+------------------+--------------------+-----------------+---------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+-----------------+---------+------------------+----------------------------+------------------+-------------------+-------------------+--------------------+-------------------+--------------------+----------------------+-----------------------+------------------+-------------------+------------------+-------------------+-----------------+--------------------+------------------+-------------------+-------------------+-------------------+------------------+----------+--------+---------+-----------------------------------+------------------------------------+------------------------+-------------------------+----------------------+-----------------------+----------------------+-----------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+-------------+-----------+--------------+--------------+--------------+--------------+------------+---------------+--------------------------+------------------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"property_id\", \"hos_state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 4 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General feature creation \n",
    "1. sale_date to sale_month, sale_day, sale_year\n",
    "2. prev_sale_date to prev_sale_month, prev_sale_day, prev_sale_year\n",
    "3. Median_Income to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sale_date\n",
    "df = df.withColumn('sale_month', F.month(col(\"sale_date\")))\\\n",
    "    .withColumn('sale_day', date_format(col(\"sale_date\"), \"d\"))\\\n",
    "    .withColumn('sale_year', F.year(col(\"sale_date\")))\n",
    "#prev_sale_date\n",
    "df = df.withColumn('prev_sale_month', F.month(col(\"prev_sale_date\")))\\\n",
    "    .withColumn('prev_sale_day', date_format(col(\"sale_date\"), \"d\"))\\\n",
    "    .withColumn('prev_sale_year', F.year(col(\"prev_sale_date\")))\n",
    "#Median_Income\n",
    "df = df.withColumn('Median_Income', df['Median_Income'].cast('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### city, state and zip to categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e6b80107eb96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"Index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"Index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"Vector\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/Anaconda3-5.1.0-hadoop/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert city, state and zip to numeric categorical\n",
    "for y in ['city', 'state', 'zip5']:\n",
    "    print(y)\n",
    "    indexer = StringIndexer(inputCol=str(y), outputCol=str(y)+\"Index\")\n",
    "    ohe = OneHotEncoder(inputCol = str(y)+\"Index\", outputCol = str(y)+\"Vector\")\n",
    "    df = indexer.fit(df).transform(df)\n",
    "    df = ohe.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip5: string (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- property_id: string (nullable = true)\n",
      " |-- sale_date: date (nullable = true)\n",
      " |-- sale_price: float (nullable = false)\n",
      " |-- year_built: string (nullable = true)\n",
      " |-- num_sales: long (nullable = false)\n",
      " |-- zip_num_schools: long (nullable = true)\n",
      " |-- city_num_schools: long (nullable = true)\n",
      " |-- zip_st_ratio: double (nullable = false)\n",
      " |-- city_st_ratio: double (nullable = false)\n",
      " |-- CPIHOSNS: double (nullable = false)\n",
      " |-- ZVHI: double (nullable = false)\n",
      " |-- Median_Income: string (nullable = true)\n",
      " |-- hos_state: string (nullable = true)\n",
      " |-- sum(count): long (nullable = true)\n",
      " |-- avg(Hospital overall rating): double (nullable = false)\n",
      " |-- CHILDREN_CNT: long (nullable = true)\n",
      " |-- CHILDREN_RATE: double (nullable = false)\n",
      " |-- CRITICAL ACCESS_CNT: long (nullable = true)\n",
      " |-- CRITICAL ACCESS_RATE: double (nullable = false)\n",
      " |-- GENERAL ACUTE CARE_CNT: long (nullable = true)\n",
      " |-- GENERAL ACUTE CARE_RATE: double (nullable = false)\n",
      " |-- LONG TERM CARE_CNT: long (nullable = true)\n",
      " |-- MILITARY_CNT: long (nullable = true)\n",
      " |-- MILITARY_RATE: double (nullable = false)\n",
      " |-- PSYCHIATRIC_CNT: long (nullable = true)\n",
      " |-- PSYCHIATRIC_RATE: double (nullable = false)\n",
      " |-- REHABILITATION_CNT: long (nullable = true)\n",
      " |-- SPECIAL_CNT: long (nullable = true)\n",
      " |-- SPECIAL_RATE: double (nullable = false)\n",
      " |-- WOMEN_CNT: long (nullable = true)\n",
      " |-- GOVERNMENT - DISTRICT/AUTHORITY_CNT: long (nullable = true)\n",
      " |-- GOVERNMENT - DISTRICT/AUTHORITY_RATE: double (nullable = false)\n",
      " |-- GOVERNMENT - FEDERAL_CNT: long (nullable = true)\n",
      " |-- GOVERNMENT - FEDERAL_RATE: double (nullable = false)\n",
      " |-- GOVERNMENT - LOCAL_CNT: long (nullable = true)\n",
      " |-- GOVERNMENT - LOCAL_RATE: double (nullable = false)\n",
      " |-- GOVERNMENT - STATE_CNT: long (nullable = true)\n",
      " |-- NON-PROFIT_CNT: long (nullable = true)\n",
      " |-- NON-PROFIT_RATE: double (nullable = false)\n",
      " |-- NOT AVAILABLE_CNT: long (nullable = true)\n",
      " |-- NOT AVAILABLE_RATE: double (nullable = false)\n",
      " |-- PROPRIETARY_CNT: long (nullable = true)\n",
      " |-- PROPRIETARY_RATE: double (nullable = false)\n",
      " |-- prev_sale_date: date (nullable = true)\n",
      " |-- prev_sale_price: float (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### property_type clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create pipeline\n",
    "# tokenization\n",
    "tokenization = Tokenizer(inputCol=\"property_type\", outputCol=\"p_words\")\n",
    "# stopwords\n",
    "stopwords = StopWordsRemover(inputCol= \"p_words\", outputCol=\"p_filtered\")\n",
    "# some form of dimensionality reduction, word2vec\n",
    "word2vec = Word2Vec(vectorSize=5, minCount=0, inputCol=\"p_filtered\", outputCol=\"propertyVector\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    tokenization,\n",
    "    stopwords,\n",
    "    word2vec\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_pipeline = pipeline.fit(df)\n",
    "df = pipeline.fit(df).transform(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans\n",
    "kmeans = KMeans(featuresCol='propertyVector', predictionCol='propertyClusters', k=10, seed=123, maxIter=5)\n",
    "k_mod = kmeans.fit(df)\n",
    "df = k_mod.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variables with low stddev\n",
    "summary = df.describe().toPandas()\\\n",
    "    .set_index(\"summary\").T\\\n",
    "    .sort_values(by=\"stddev\")\n",
    "summary['stddev'] = pd.to_numeric(summary['stddev'])\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = summary[summary['stddev'] == 0].index\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('physical_address', 'count(MURDER)', 'GOVERNMENT - STATE_RATE',\n",
    "       'null_RATE', 'null_CNT', 'WOMEN_RATE', 'REHABILITATION_RATE',\n",
    "       'avg(crime_rate_per_100000)', 'LONG TERM CARE_RATE',\n",
    "       'CHRONIC DISEASE_RATE', 'CHRONIC DISEASE_CNT', 'count(ROBBERY)',\n",
    "       'count(RAPE)', 'sum(population)', 'num_units', 'count(MVTHEFT)',\n",
    "       'count(ARSON)', 'count(AGASSLT)', 'count(BURGLRY)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 5 - Some data viz/exploration pre model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation with y variable (sale_price)\n",
    "y_corr = pd.DataFrame(columns=['Columns', 'Correlation Value'])\n",
    "for x in df.columns:\n",
    "    try:\n",
    "        print(x)\n",
    "        temp = pd.DataFrame([[x, df.corr(\"sale_price\", x)]], columns=['Columns', 'Correlation Value'])\n",
    "        y_corr = y_corr.append(temp)\n",
    "    except:\n",
    "        pass\n",
    "y_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all x variable correlation\n",
    "x_corr = pd.DataFrame({\"Variables\" : df.columns})\n",
    "for x in df.columns:\n",
    "    temp2 = pd.DataFrame()\n",
    "    for y in df.columns:\n",
    "        print(str(x) + \" and \" + str(y))\n",
    "        try:\n",
    "            temp = pd.DataFrame([[df.corr(x,y)]], columns=[x])\n",
    "#             temp = pd.DataFrame([[\"CORR\"]], columns=[x])\n",
    "            temp2 = temp2.append(temp)\n",
    "        except:\n",
    "            temp = pd.DataFrame([[\"N/A\"]], columns=[x])\n",
    "            temp2 = temp2.append(temp)\n",
    "    x_corr = pd.concat([x_corr,temp2.reset_index().drop(columns=\"index\")], axis=1)\n",
    "x_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sale_price'].mean())\n",
    "print(df['sale_price'].min())\n",
    "print(df['sale_price'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sale price over time\n",
    "# sale price vs year_built\n",
    "# sale price vs sale_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 6 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"city\", \"state\", \"zip5\", \"property_type\", \"property_id\", \"sale_price\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = (\"prev_sale_price\", \"zip_st_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df #mod_df.sample(0.05)\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = predictors, outputCol = 'features')\n",
    "vinput_data = vectorAssembler.transform(input_data)\n",
    "vinput_data = vinput_data.select(['features', 'sale_price'])\n",
    "# vinput_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "train_df, test_df = vinput_data.randomSplit([.7,.3],seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "elasticNetParam = 1, then Lasso <br>\n",
    "regParam = 1, then Ridge <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.174983366984032,9418.7880375339]\n",
      "Intercept: 364139.54091635754\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='sale_price', maxIter=5, regParam=1, elasticNetParam=0)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8939274.922702\n",
      "r2: 0.019213\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o798.showString.\n: org.apache.spark.SparkException: Could not execute broadcast in 300 secs. You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:150)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:375)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:144)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:136)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenOuter(BroadcastHashJoinExec.scala:282)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:104)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:189)\n\tat org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:65)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:189)\n\tat org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:85)\n\tat org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:206)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:189)\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:362)\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:362)\n\tat org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:125)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:532)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:586)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.doExecute(SortMergeJoinExec.scala:150)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.doExecute(SortMergeJoinExec.scala:150)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.window.WindowExec.doExecute(WindowExec.scala:302)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.doExecute(SortMergeJoinExec.scala:150)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:271)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:339)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)\n\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:146)\n\t... 313 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-22d9bb30cfc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sale_price\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m,\u001b[0m                  \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sale_price\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R Squared (R2) on test data = %g\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlr_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o798.showString.\n: org.apache.spark.SparkException: Could not execute broadcast in 300 secs. You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:150)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:375)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:144)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:136)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenOuter(BroadcastHashJoinExec.scala:282)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:104)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:189)\n\tat org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:65)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:189)\n\tat org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:85)\n\tat org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:206)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:189)\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:362)\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:362)\n\tat org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:125)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:98)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:532)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:586)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.doExecute(SortMergeJoinExec.scala:150)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.doExecute(SortMergeJoinExec.scala:150)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.window.WindowExec.doExecute(WindowExec.scala:302)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.doExecute(SortMergeJoinExec.scala:150)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:379)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:271)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:615)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:339)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)\n\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:146)\n\t... 313 more\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"sale_price\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"sale_price\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, \n",
    "regParam=0.0)\n",
    "model = glr.fit(dataset)\n",
    "summary = model.summary\n",
    "print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(summary.tValues))\n",
    "print(\"P Values: \" + str(summary.pValues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'sale_price', maxDepth=1)\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"sale_price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'MV', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'MV', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"MV\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
